{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datamining-a02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Ke3LBfULRYg18UIrREssATZfO3QcdDGy",
      "authorship_tag": "ABX9TyMH5lW6N9F1ecrRBAcQNMA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanfaiyazkhan/tabular_classification/blob/main/datamining_a02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG7cxexakrEb"
      },
      "source": [
        "# Assignment 2: Rohan Faiyaz Khan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHMJNFTxEsvl"
      },
      "source": [
        "#! pip install -Uqq numpy pandas scikit-learn"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGcYfbh0Fx_w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from pprint import pprint\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEbqDAtUx5U9"
      },
      "source": [
        "## Trial 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWlxKIfNC5pC"
      },
      "source": [
        "For this assignment we will create a model that predict product ratings. Let's first run through trial 0 using the same code as provided in the walkthrough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WThbyY6gHgIe"
      },
      "source": [
        "# Load data\n",
        "data = pd.read_csv('./drive/MyDrive/Colab Notebooks/train_new.csv').sample(frac=1)\n",
        "# Ensure rating is one of the 5 levels\n",
        "data = data.loc[data['rating'].isin([1, 2, 3, 4, 5])]\n",
        "# Fill null values\n",
        "data = data.fillna(0)\n",
        "# Drop columns that we can intuit are not related to the rating. \n",
        "# For example id is randomly generated and hence is not relevant to rating\n",
        "data = data.drop(['merchant_id', 'merchant_profile_picture', 'id', 'tags'], axis=1)\n"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Uca9NNIZeR"
      },
      "source": [
        "# Split training and validation data with a 70-30 split\n",
        "msk = np.random.rand(len(data)) < 0.7\n",
        "tr = data[msk]\n",
        "val = data[~msk]"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEPtjm1xyo78",
        "outputId": "2f3b6561-8cfb-420b-f854-97fe19b89762"
      },
      "source": [
        "dict_cat = {}\n",
        "\n",
        "cat_cols = tr.columns[tr.dtypes==object].to_list()\n",
        "\n",
        "# this function will encode columns that are strings as categorical digits\n",
        "def cat_digit(col):  \n",
        "    # build the mapping\n",
        "    encoded = col.astype('category').cat.codes\n",
        "    # store the mapping\n",
        "    dict_cat[col.name] = dict(zip(np.asarray(col), np.asarray(encoded)))\n",
        "    return encoded\n",
        "\n",
        "# for each categorical feature, apply cat_digit where we build the mapping and transform the data\n",
        "# this is for the training set (where we build the mapping)\n",
        "tr[cat_cols] = tr[cat_cols].apply(lambda col: cat_digit(col))\n",
        "\n",
        "\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hObhMxKITKQN"
      },
      "source": [
        "While encoding, we are also saving the encoding-category pairs in the category dictionary `dict_cat`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNGiLbRW0Hj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da49ea23-ebc8-4125-a789-3cf8bfba7aa1"
      },
      "source": [
        "print('categorical features')\n",
        "pprint(list(dict_cat.keys()))"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical features\n",
            "['currency_buyer',\n",
            " 'product_color',\n",
            " 'product_variation_size_id',\n",
            " 'shipping_option_name',\n",
            " 'urgency_text',\n",
            " 'origin_country',\n",
            " 'merchant_title',\n",
            " 'merchant_name',\n",
            " 'merchant_info_subtitle',\n",
            " 'theme',\n",
            " 'crawl_month']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0YKrZdgenEM",
        "outputId": "6baea1b7-6bcc-49dc-b7c5-6a74c30744a6"
      },
      "source": [
        "print('Lets see what the mapping for column origin_country :')\n",
        "pprint(dict_cat['origin_country'])\n",
        "print('It is a string to integer mapping')"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lets see what the mapping for column origin_country :\n",
            "{0: 0, 'CN': 1, 'GB': 2, 'US': 3, 'VE': 4}\n",
            "It is a string to integer mapping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "figf_kLOTHgL"
      },
      "source": [
        "We can see how the mapping inside `dict_cat` looks like for one category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "nMlKyzdThUCS",
        "outputId": "8c8e036a-f313-4d4f-fd94-48f09aaa1c04"
      },
      "source": [
        "# then we will use the mappings built from the training set, to transform the validation set\n",
        "val[cat_cols] = val[cat_cols].apply(lambda col: col.map(dict_cat[col.name]))\n",
        "# for string values that not seen in training set, we replace it with -1\n",
        "val = val.fillna(-1)\n",
        "val"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>retail_price</th>\n",
              "      <th>currency_buyer</th>\n",
              "      <th>units_sold</th>\n",
              "      <th>uses_ad_boosts</th>\n",
              "      <th>rating</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>badges_count</th>\n",
              "      <th>badge_local_product</th>\n",
              "      <th>badge_product_quality</th>\n",
              "      <th>badge_fast_shipping</th>\n",
              "      <th>product_color</th>\n",
              "      <th>product_variation_size_id</th>\n",
              "      <th>product_variation_inventory</th>\n",
              "      <th>shipping_option_name</th>\n",
              "      <th>shipping_option_price</th>\n",
              "      <th>shipping_is_express</th>\n",
              "      <th>countries_shipped_to</th>\n",
              "      <th>inventory_total</th>\n",
              "      <th>has_urgency_banner</th>\n",
              "      <th>urgency_text</th>\n",
              "      <th>origin_country</th>\n",
              "      <th>merchant_title</th>\n",
              "      <th>merchant_name</th>\n",
              "      <th>merchant_info_subtitle</th>\n",
              "      <th>merchant_rating_count</th>\n",
              "      <th>merchant_rating</th>\n",
              "      <th>merchant_has_profile_picture</th>\n",
              "      <th>theme</th>\n",
              "      <th>crawl_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1049</th>\n",
              "      <td>9.0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>985</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>7889</td>\n",
              "      <td>3.995056</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>16.0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>514</td>\n",
              "      <td>4.217899</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20000</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>16013</td>\n",
              "      <td>4.108849</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>8.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>30</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>88193</td>\n",
              "      <td>4.080891</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>7.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>7023</td>\n",
              "      <td>4.235939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>8.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>610</td>\n",
              "      <td>3.814754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>11.0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>357</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>366.0</td>\n",
              "      <td>39381</td>\n",
              "      <td>4.066326</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>197</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2610</td>\n",
              "      <td>4.158238</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>9.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4335</td>\n",
              "      <td>4.057209</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045</th>\n",
              "      <td>8.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>23832</td>\n",
              "      <td>4.020435</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>334 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  retail_price  ...  theme  crawl_month\n",
              "1049    9.0            50  ...      0            0\n",
              "748    16.0            14  ...      0            0\n",
              "197     6.0             6  ...      0            0\n",
              "331     8.0             7  ...      0            0\n",
              "655     7.0             6  ...      0            0\n",
              "...     ...           ...  ...    ...          ...\n",
              "489     8.0             7  ...      0            0\n",
              "865    11.0            10  ...      0            0\n",
              "846     5.0             5  ...      0            0\n",
              "395     9.0             8  ...      0            0\n",
              "1045    8.0             9  ...      0            0\n",
              "\n",
              "[334 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUyefbwjisDA"
      },
      "source": [
        "# The y or target variable will be the rating column\n",
        "tr_y = tr['rating']\n",
        "# The x or features will be every column except rating\n",
        "tr_x = tr.drop('rating', axis=1)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oRZ9eGmUFzZ"
      },
      "source": [
        "The model we are using to train is LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJqR0ojTm6k6",
        "outputId": "a2340e34-60f9-48e2-f1fc-1472e7b2a6bf"
      },
      "source": [
        "clf = LogisticRegression().fit(tr_x, tr_y)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KyTS_Rtm9hm"
      },
      "source": [
        "# Similar to how we extracted x and y from the training data, we will do the same for validation data\n",
        "val_y = val['rating']\n",
        "val_x = val.drop('rating', axis=1)\n",
        "pred_val = clf.predict(val_x)"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7s-uC5RnJQg",
        "outputId": "721b39ad-36d6-47eb-c313-82ace6be0e98"
      },
      "source": [
        "# F1 score is a weighted measure of accuracy. This can be our metric for evaluation.\n",
        "val_score = f1_score(val_y, pred_val, average='micro')\n",
        "# Let's check our baseline\n",
        "print(val_score)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6976047904191617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vn-UCBszNA"
      },
      "source": [
        "Going through the entire process, I have a few important observations.\n",
        "1. The validation data is split from the data through random sampling, and the ratio of training data to validation data is 70-30.\n",
        "2. Categorical encoding was used to on non-numeric columns\n",
        "3. Logistic regression was used with no regularization or constraints\n",
        "\n",
        "Let's think about what we can change for trial 1.\n",
        "\n",
        "Let's see which features are not particularly related to the rating. We can observe this by looking at the correlation matrix and observing the rating column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcdvTaPl7x1N"
      },
      "source": [
        "## Trial 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaU63_NhmBNj"
      },
      "source": [
        "The first problem is that we have too many features and not all of them are best suited for this classification task. \n",
        "\n",
        "I am not sure what the best approach of reducing features is but perhaps we can start with observing correlations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4knJaC11QsL",
        "outputId": "58933de5-dea8-43da-a4a8-9c7ff0fd8e5c"
      },
      "source": [
        "tr.corr()['rating'].apply(abs).sort_values()"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shipping_is_express             0.000902\n",
              "uses_ad_boosts                  0.001883\n",
              "badge_local_product             0.002224\n",
              "merchant_has_profile_picture    0.013531\n",
              "urgency_text                    0.015481\n",
              "has_urgency_banner              0.015637\n",
              "countries_shipped_to            0.018149\n",
              "badge_fast_shipping             0.019665\n",
              "merchant_title                  0.021641\n",
              "units_sold                      0.025774\n",
              "merchant_name                   0.028643\n",
              "shipping_option_name            0.031221\n",
              "rating_count                    0.041481\n",
              "product_variation_inventory     0.065737\n",
              "merchant_rating_count           0.070600\n",
              "inventory_total                 0.082831\n",
              "product_variation_size_id       0.095825\n",
              "retail_price                    0.099185\n",
              "origin_country                  0.106885\n",
              "product_color                   0.108771\n",
              "merchant_info_subtitle          0.165314\n",
              "shipping_option_price           0.192024\n",
              "price                           0.225098\n",
              "badges_count                    0.231472\n",
              "merchant_rating                 0.239791\n",
              "badge_product_quality           0.297357\n",
              "rating                          1.000000\n",
              "currency_buyer                       NaN\n",
              "theme                                NaN\n",
              "crawl_month                          NaN\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sHPPRQT2iyl"
      },
      "source": [
        "We can observe that there is low correlation between rating and some features whereas some others have `NaN`. Training with these features may cause overfitting so let's try dropping the five least correlated features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLLaa88x2iXR",
        "outputId": "26455f60-7a6b-47dd-ade2-04e185ef2d12"
      },
      "source": [
        "sorted_correlations = tr.corr()['rating'].fillna(0).apply(abs).sort_values()\n",
        "least_correlated = sorted_correlations[:5]\n",
        "least_correlated"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crawl_month            0.000000\n",
              "currency_buyer         0.000000\n",
              "theme                  0.000000\n",
              "shipping_is_express    0.000902\n",
              "uses_ad_boosts         0.001883\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMm6e5fU3ffx"
      },
      "source": [
        "tr = tr.drop([*(least_correlated.index)], axis=1)\n"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FELAvJwUTe5"
      },
      "source": [
        "We need to drop the same columns on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csmq13zz5QxX"
      },
      "source": [
        "val = val.drop([*(least_correlated.index)], axis=1)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DURm4KwUa0E"
      },
      "source": [
        "Just like before let's train the LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftoGcU5f7KT-",
        "outputId": "079ea163-078b-4d01-d1b5-8cddb6d5f289"
      },
      "source": [
        "tr_y = tr['rating']\n",
        "tr_x = tr.drop('rating', axis=1)\n",
        "clf = LogisticRegression().fit(tr_x, tr_y)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCTr7-LA7VFE"
      },
      "source": [
        "val_y = val['rating']\n",
        "val_x = val.drop('rating', axis=1)\n",
        "pred_val = clf.predict(val_x)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9j5j1bs7ebE",
        "outputId": "7c602b7a-07f8-4fd5-ffdc-281fff3d06d7"
      },
      "source": [
        "val_score = f1_score(val_y, pred_val, average='micro')\n",
        "print(val_score)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7065868263473054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYMAwqQO73Y8"
      },
      "source": [
        "So our accuracy did not particularly change even though we dropped 5 columns. This is a good sign, as we reduced the complexity of our model without loss of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDCMVcAtkoW6"
      },
      "source": [
        "## Trial 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqGKzYzWm7FC"
      },
      "source": [
        "Let's take this one step further and drop all columns below a certain threshold of correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ihODqKo7_x8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e7d7f3-c94a-47ea-9a54-065db32ec95a"
      },
      "source": [
        "# recreate the data sets\n",
        "tr = data[msk]\n",
        "val = data[~msk]\n",
        "tr[cat_cols] = tr[cat_cols].apply(lambda col: cat_digit(col))\n",
        "val[cat_cols] = val[cat_cols].apply(lambda col: col.map(dict_cat[col.name]))\n",
        "val = val.fillna(-1)\n",
        "\n",
        "feature_correlation_threshold = 0.04 # new hyperparam"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doyyNelVASqA",
        "outputId": "e7a6fd9d-f3c5-4ba0-82f7-8192a8de48b4"
      },
      "source": [
        "tr.corr()['rating'].fillna(0).apply(abs).sort_values()"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crawl_month                     0.000000\n",
              "currency_buyer                  0.000000\n",
              "theme                           0.000000\n",
              "shipping_is_express             0.000902\n",
              "uses_ad_boosts                  0.001883\n",
              "badge_local_product             0.002224\n",
              "merchant_has_profile_picture    0.013531\n",
              "urgency_text                    0.015481\n",
              "has_urgency_banner              0.015637\n",
              "countries_shipped_to            0.018149\n",
              "badge_fast_shipping             0.019665\n",
              "merchant_title                  0.021641\n",
              "units_sold                      0.025774\n",
              "merchant_name                   0.028643\n",
              "shipping_option_name            0.031221\n",
              "rating_count                    0.041481\n",
              "product_variation_inventory     0.065737\n",
              "merchant_rating_count           0.070600\n",
              "inventory_total                 0.082831\n",
              "product_variation_size_id       0.095825\n",
              "retail_price                    0.099185\n",
              "origin_country                  0.106885\n",
              "product_color                   0.108771\n",
              "merchant_info_subtitle          0.165314\n",
              "shipping_option_price           0.192024\n",
              "price                           0.225098\n",
              "badges_count                    0.231472\n",
              "merchant_rating                 0.239791\n",
              "badge_product_quality           0.297357\n",
              "rating                          1.000000\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSHAjYBRlIw0",
        "outputId": "a90ec3f1-3a5c-4de0-a863-44a796979a05"
      },
      "source": [
        "# this time we use a condition to determine which columns are unrelated\n",
        "above_correlation_thresh = tr.corr()['rating'].fillna(0).apply(abs) >= feature_correlation_threshold\n",
        "least_correlated = above_correlation_thresh[above_correlation_thresh == False].index\n",
        "least_correlated"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['currency_buyer', 'units_sold', 'uses_ad_boosts', 'badge_local_product',\n",
              "       'badge_fast_shipping', 'shipping_option_name', 'shipping_is_express',\n",
              "       'countries_shipped_to', 'has_urgency_banner', 'urgency_text',\n",
              "       'merchant_title', 'merchant_name', 'merchant_has_profile_picture',\n",
              "       'theme', 'crawl_month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqy8qayZlZUJ"
      },
      "source": [
        "tr = tr.drop([*least_correlated], axis=1)\n",
        "val = val.drop([*least_correlated], axis=1)"
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "07lP_8B1lfHn",
        "outputId": "be003180-59ec-48a0-d31a-ead8ef5f3f91"
      },
      "source": [
        "tr"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>retail_price</th>\n",
              "      <th>rating</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>badges_count</th>\n",
              "      <th>badge_product_quality</th>\n",
              "      <th>product_color</th>\n",
              "      <th>product_variation_size_id</th>\n",
              "      <th>product_variation_inventory</th>\n",
              "      <th>shipping_option_price</th>\n",
              "      <th>inventory_total</th>\n",
              "      <th>origin_country</th>\n",
              "      <th>merchant_info_subtitle</th>\n",
              "      <th>merchant_rating_count</th>\n",
              "      <th>merchant_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>8.00</td>\n",
              "      <td>59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>223</td>\n",
              "      <td>58154</td>\n",
              "      <td>3.871359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>12.00</td>\n",
              "      <td>17</td>\n",
              "      <td>4.0</td>\n",
              "      <td>103</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>31</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>212</td>\n",
              "      <td>20478</td>\n",
              "      <td>3.910343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>14.00</td>\n",
              "      <td>12</td>\n",
              "      <td>4.0</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>56</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>154</td>\n",
              "      <td>288</td>\n",
              "      <td>3.729167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>5.92</td>\n",
              "      <td>9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>495</td>\n",
              "      <td>5106</td>\n",
              "      <td>4.212887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>9.00</td>\n",
              "      <td>48</td>\n",
              "      <td>4.0</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>31</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>6632</td>\n",
              "      <td>3.748794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>8.00</td>\n",
              "      <td>7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5641</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>64</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>70773</td>\n",
              "      <td>4.038320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>12.00</td>\n",
              "      <td>11</td>\n",
              "      <td>4.0</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>456</td>\n",
              "      <td>4811</td>\n",
              "      <td>4.194554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>5.85</td>\n",
              "      <td>13</td>\n",
              "      <td>3.0</td>\n",
              "      <td>602</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>61</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>215</td>\n",
              "      <td>25631</td>\n",
              "      <td>3.894737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>14.00</td>\n",
              "      <td>76</td>\n",
              "      <td>4.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>288</td>\n",
              "      <td>51369</td>\n",
              "      <td>3.968269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>12.00</td>\n",
              "      <td>11</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>36</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>1452</td>\n",
              "      <td>3.735537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>759 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  retail_price  ...  merchant_rating_count  merchant_rating\n",
              "803    8.00            59  ...                  58154         3.871359\n",
              "641   12.00            17  ...                  20478         3.910343\n",
              "473   14.00            12  ...                    288         3.729167\n",
              "993    5.92             9  ...                   5106         4.212887\n",
              "1091   9.00            48  ...                   6632         3.748794\n",
              "...     ...           ...  ...                    ...              ...\n",
              "32     8.00             7  ...                  70773         4.038320\n",
              "594   12.00            11  ...                   4811         4.194554\n",
              "449    5.85            13  ...                  25631         3.894737\n",
              "576   14.00            76  ...                  51369         3.968269\n",
              "135   12.00            11  ...                   1452         3.735537\n",
              "\n",
              "[759 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTFm3Rvkn2H8",
        "outputId": "ebbcc9b2-b7e7-447e-c9f4-a99e017fa571"
      },
      "source": [
        "tr_y = tr['rating']\n",
        "tr_x = tr.drop('rating', axis=1)\n",
        "clf = LogisticRegression().fit(tr_x, tr_y)"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxGyJYlAoqOE"
      },
      "source": [
        "val_y = val['rating']\n",
        "val_x = val.drop('rating', axis=1)\n",
        "pred_val = clf.predict(val_x)"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ8Kxpt6orIk",
        "outputId": "c98c1768-5939-481b-c60f-f0a8bfbf376e"
      },
      "source": [
        "val_score = f1_score(val_y, pred_val, average='micro')\n",
        "print(val_score)"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7275449101796408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V1p3E6opC25"
      },
      "source": [
        "Some improvement 🤷‍♀️. This shows a lot of the features were simply adding noise to the model. Now we are still facing some issues with Logistic Regression so let's see if we can improve on that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXbYJ4KDuOfg"
      },
      "source": [
        "# Trial 3\n",
        "\n",
        "One observation throughout the process is that the everytime we run `fit`, we get a warning that says `ConvergenceWarning: lbfgs failed to converge (status=1):\n",
        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.` The warning also suggests that we do some preprocessing.\n",
        "\n",
        "So let's do some scaling before we train with our data. ⚖️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHl4JHcNH5BH"
      },
      "source": [
        "def scale_x(tr_x, val_x):\n",
        "  sc = StandardScaler()\n",
        "  tr_x_scaled = sc.fit_transform(tr_x)\n",
        "  val_x_scaled = sc.transform(val_x)\n",
        "  return tr_x_scaled, val_x_scaled, sc"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmUJfra4I7fD"
      },
      "source": [
        "Let's check how our scaled data looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoxAz5eHLmN0"
      },
      "source": [
        "tr_x_scaled, val_x_scaled,sc = scale_x(tr_x, val_x)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWden2fcU2ZP"
      },
      "source": [
        "The scaled data is an array, not a dataframe. Hence we can preview what it looks like through indexing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtWvhhl-LquO",
        "outputId": "8f311d13-8bb8-4188-f24f-11f8d630d31f"
      },
      "source": [
        "tr_x_scaled[:3]"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05234539,  1.12871388, -0.4203344 , -0.31667239, -0.3034573 ,\n",
              "        -0.34640061,  1.18170743, -1.28111699,  0.69521194,  0.06381369,\n",
              "        -0.09786223, -0.48583484,  0.29495485, -0.79415813],\n",
              "       [ 1.00073663, -0.20229419, -0.39313653, -0.31667239, -0.3034573 ,\n",
              "         1.12871724, -0.82841346,  0.81229756,  0.69521194,  0.06381369,\n",
              "        -0.09786223, -0.55069206, -0.08247402, -0.60536346],\n",
              "       [ 1.52727764, -0.36074753, -0.35421545, -0.31667239, -0.3034573 ,\n",
              "        -0.65010135,  0.84668728, -1.04851538,  1.69647544,  0.06381369,\n",
              "        -0.09786223, -0.89266647, -0.28473246, -1.48277699]])"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0NzHCOKbjE"
      },
      "source": [
        "Let's train with this now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohEtT26Tubys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c169a50e-850c-44e8-b0d2-83c941c62499"
      },
      "source": [
        "clf = LogisticRegression().fit(tr_x_scaled, tr_y)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-_unyg2NjiX"
      },
      "source": [
        "We are still getting this warning. Perhaps there is more we need to change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K4rTV5OKqCX",
        "outputId": "2e70ab6a-aa20-4a8b-f7ff-153ca9883b04"
      },
      "source": [
        "pred_val = clf.predict(val_x_scaled)\n",
        "val_score = f1_score(val_y, pred_val, average='micro')\n",
        "print(val_score)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7455089820359282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxXaNxO_PGPA"
      },
      "source": [
        "That was barely any change at all 🤦‍♂️\n",
        "\n",
        "Let's peak at the confusion matrix and classification report to see what is going on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JqQrALcXRnVa",
        "outputId": "ffc43f99-1493-4245-c897-bd8c14ecc2f5"
      },
      "source": [
        "mat = confusion_matrix(val_y, pred_val)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBOk2IsLVlA8",
        "outputId": "69883d75-2434-42d1-f443-58edfb697ff8"
      },
      "source": [
        "print(classification_report(val_y, pred_val))"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       0.00      0.00      0.00        36\n",
            "         4.0       0.73      1.00      0.84       243\n",
            "         5.0       0.00      0.00      0.00        53\n",
            "\n",
            "    accuracy                           0.73       334\n",
            "   macro avg       0.18      0.25      0.21       334\n",
            "weighted avg       0.53      0.73      0.61       334\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmE87DGVYiJ"
      },
      "source": [
        "It appears our model is predicting everything as the mean value of 4. This is not ideal 📉"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnw4RJN2PQXg"
      },
      "source": [
        "# Trial 4\n",
        "\n",
        "So maybe we are approaching this all wrong. Perhaps the data is not suited to Logistic Regression? Let's try a different model. This is a classification problem and hence we have decision trees and support vector machines at our disposal. Let's try a decision tree based model, RandomForest. For the initial test we will use unscaled data (minus the redundant columns)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPJ-P2EPPOnc"
      },
      "source": [
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-lmJKkOSPur"
      },
      "source": [
        "rfc.fit(tr_x, tr_y)\n",
        "pred_val = rfc.predict(val_x)"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLW3c4--VyOW",
        "outputId": "e8a225d7-f0f3-46dc-de6a-f7f633d6de36"
      },
      "source": [
        "val_score = f1_score(val_y, pred_val, average='micro')\n",
        "print(val_score)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.811377245508982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn9PuBjkV1B6",
        "outputId": "bf7a73d8-685e-4b45-935d-1248af7343cd"
      },
      "source": [
        "print(classification_report(val_y, pred_val))"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         2.0       1.00      0.50      0.67         2\n",
            "         3.0       0.53      0.25      0.34        36\n",
            "         4.0       0.83      0.95      0.89       243\n",
            "         5.0       0.76      0.55      0.64        53\n",
            "\n",
            "    accuracy                           0.81       334\n",
            "   macro avg       0.78      0.56      0.63       334\n",
            "weighted avg       0.79      0.81      0.79       334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBxuAyUjWjKD"
      },
      "source": [
        "Okay, so without any hyperparameter tweaking we already have a good accuracy. However this model is likely to overfitted to the training data. Let's improve our model a bit by making it more robust and maintainable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k11wjOBgY9Hv"
      },
      "source": [
        "## Trial 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzRThYkzaKsj"
      },
      "source": [
        "One thing we can do is tweak the hyperparameters of a RandomForest 👾👾👾\n",
        "\n",
        "Let's write a function that initializes a random forest with some sensible hyperparams. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8cmjM_XY7PM"
      },
      "source": [
        "def rf(xs, y, n_estimators=50, max_samples=600,\n",
        "       max_features=0.5, min_samples_leaf=5, max_leaf_nodes=400, **kwargs):\n",
        "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features,\n",
        "        min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes, oob_score=True).fit(xs, y)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "datDWZolaaaS"
      },
      "source": [
        "rfc = rf(tr_x, tr_y, )"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHB4_CsCall-"
      },
      "source": [
        "def get_f1_accuracy(m, val_x, val_y):\n",
        "  pred_val = m.predict(val_x)\n",
        "  return f1_score(val_y, pred_val, average='micro')"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGll-ipBbFNy",
        "outputId": "f0b9aa96-94eb-456d-caff-7be13f961953"
      },
      "source": [
        "get_f1_accuracy(rfc, val_x, val_y)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7784431137724551"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gSSEr-ncL7p"
      },
      "source": [
        "So this is a bit finicky because I ran this step lots of times and sometimes I got improvements in performance and sometimes I did not. This indicates I will need to experiment a bit more with the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8tGIkPYcj2d",
        "outputId": "5152314b-7b05-476d-afaf-51c1c4ca4120"
      },
      "source": [
        "print(classification_report(val_y, pred_val))"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         2.0       1.00      0.50      0.67         2\n",
            "         3.0       0.53      0.25      0.34        36\n",
            "         4.0       0.83      0.95      0.89       243\n",
            "         5.0       0.76      0.55      0.64        53\n",
            "\n",
            "    accuracy                           0.81       334\n",
            "   macro avg       0.78      0.56      0.63       334\n",
            "weighted avg       0.79      0.81      0.79       334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLIIL0NxgM3M"
      },
      "source": [
        "## Trial 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQACXF1noANz"
      },
      "source": [
        "So now we know that tuning hyperparameters can help improve performance. However, a bottleneck in the performance is still the data which has too many features. Now that we have a simple RandomForest, we can analyze feature importance. 🔍"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38CBAA0ooIIz"
      },
      "source": [
        "def rf_feat_importance(m, df):\n",
        "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
        "                       ).sort_values('imp', ascending=False)"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "dEFa0E_l3eWV",
        "outputId": "849482de-7cc8-4132-9729-51ff5fb2deec"
      },
      "source": [
        "feat_importance = rf_feat_importance(rfc, tr_x)\n",
        "feat_importance"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cols</th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rating_count</td>\n",
              "      <td>0.315273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>merchant_rating_count</td>\n",
              "      <td>0.124546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>merchant_rating</td>\n",
              "      <td>0.107922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>price</td>\n",
              "      <td>0.088318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>merchant_info_subtitle</td>\n",
              "      <td>0.074057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>badge_product_quality</td>\n",
              "      <td>0.060663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>retail_price</td>\n",
              "      <td>0.057086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>product_color</td>\n",
              "      <td>0.049855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>badges_count</td>\n",
              "      <td>0.047792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>product_variation_inventory</td>\n",
              "      <td>0.033065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>product_variation_size_id</td>\n",
              "      <td>0.022684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>shipping_option_price</td>\n",
              "      <td>0.018739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>inventory_total</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>origin_country</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           cols       imp\n",
              "2                  rating_count  0.315273\n",
              "12        merchant_rating_count  0.124546\n",
              "13              merchant_rating  0.107922\n",
              "0                         price  0.088318\n",
              "11       merchant_info_subtitle  0.074057\n",
              "4         badge_product_quality  0.060663\n",
              "1                  retail_price  0.057086\n",
              "5                 product_color  0.049855\n",
              "3                  badges_count  0.047792\n",
              "7   product_variation_inventory  0.033065\n",
              "6     product_variation_size_id  0.022684\n",
              "8         shipping_option_price  0.018739\n",
              "9               inventory_total  0.000000\n",
              "10               origin_country  0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQqRtetzW4TZ"
      },
      "source": [
        "It's easier to see the relative impact by plotting the feature importances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Ir-RUXQz7oCn",
        "outputId": "9594b9af-db6a-49da-f37f-e44ed7aa68f1"
      },
      "source": [
        "feat_importance.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39d80aaa50>"
            ]
          },
          "metadata": {},
          "execution_count": 266
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgM-4pU35XgN"
      },
      "source": [
        "Let's consider a threshold of minimum feature importance of 0.02 and drop all columns below this threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUvku_Bt8dlh"
      },
      "source": [
        "feature_importance_threshold = 0.02\n",
        "cols_to_keep = feat_importance[feat_importance.imp > feature_importance_threshold].cols"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJNxcYZZ8FQ_",
        "outputId": "ac0499a3-1e34-46a5-9533-5420e61c7e64"
      },
      "source": [
        "tr_x_imp = tr_x[cols_to_keep]\n",
        "val_x_imp = val_x[cols_to_keep]\n",
        "len(tr_x.columns), len(tr_x_imp.columns)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJXa5kss9X1x",
        "outputId": "abb01730-dc1b-461a-9b77-2112d41a31f8"
      },
      "source": [
        "rfc = rf(tr_x_imp, tr_y)\n",
        "get_f1_accuracy(rfc, val_x_imp, val_y)"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7874251497005988"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79QAEbQd-kQ5"
      },
      "source": [
        "Our accuracy from using this model is about the same even though we cut the columns by half. This is really good as we have less data to overfit to. In addition the model is simpler and easier to understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKRJa1riEn99"
      },
      "source": [
        "## Trial 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtJcss8ZJTC2"
      },
      "source": [
        "Okay, let's do another round of cleaning data. Random forests provide a built-in validation or test set, called out-of-bag data. This is the data that was skipped in the \"bagging\" process RandomForests use to sample data. We can check the error against the out-of-bag data, which is called OOB error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgKpOZBmI5Tz",
        "outputId": "955f7678-c506-42cb-9ec4-ac6c3270dbfb"
      },
      "source": [
        "tr_x_imp.columns"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['rating_count', 'merchant_rating_count', 'merchant_rating', 'price',\n",
              "       'merchant_info_subtitle', 'badge_product_quality', 'retail_price',\n",
              "       'product_color', 'badges_count', 'product_variation_inventory',\n",
              "       'product_variation_size_id'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWCyPNURGyJD"
      },
      "source": [
        "def get_oob(df):\n",
        "    m = RandomForestClassifier(n_estimators=40, min_samples_leaf=15,\n",
        "        max_samples=500, max_features=0.5, n_jobs=-1, oob_score=True)\n",
        "    m.fit(df, tr_y)\n",
        "    return m.oob_score_"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnXDH7QOKeEC"
      },
      "source": [
        "This will be our baseline OOB. If we can improve on this we may consider dropping another feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE1zTDcI-CgM",
        "outputId": "b53be45f-57c3-44fd-8748-c251eeb7cd80"
      },
      "source": [
        "get_oob(tr_x_imp)"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7457180500658761"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTn4pl6fHoF8",
        "outputId": "f9d52254-bc88-4438-fcbc-e40e2be29714"
      },
      "source": [
        "{c:get_oob(tr_x_imp.drop(c, axis=1)) for c in tr_x_imp.columns}"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'badge_product_quality': 0.7417654808959157,\n",
              " 'badges_count': 0.7457180500658761,\n",
              " 'merchant_info_subtitle': 0.7483530961791831,\n",
              " 'merchant_rating': 0.7496706192358367,\n",
              " 'merchant_rating_count': 0.7496706192358367,\n",
              " 'price': 0.7430830039525692,\n",
              " 'product_color': 0.7523056653491436,\n",
              " 'product_variation_inventory': 0.7470355731225297,\n",
              " 'product_variation_size_id': 0.7523056653491436,\n",
              " 'rating_count': 0.7140974967061924,\n",
              " 'retail_price': 0.7457180500658761}"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZbYf6ndRQsk"
      },
      "source": [
        "So we can see that if we remove either `product_variation_size_id` or `product_color`, our OOB score goes up. Let's try removing both of them and calculation F1 Loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sn4YH1pBKBY",
        "outputId": "e1f06f23-755e-4cce-9baa-0f7af10bbeb8"
      },
      "source": [
        "tr_even_fewer_cols = tr_x_imp.drop(['product_variation_size_id', 'product_color'], axis=1)\n",
        "val_even_fewer_cols = val_x_imp.drop(['product_variation_size_id', 'product_color'], axis=1)\n",
        "get_f1_accuracy(rf(tr_even_fewer_cols, tr_y), val_even_fewer_cols, val_y)"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7904191616766467"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqCB813JCFrm"
      },
      "source": [
        "So turns out dropping `product_color` and `product_variation_size_id` offers a slightly improved performance. Let's drop them from the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIWsZVlyBhlK"
      },
      "source": [
        "tr_x_imp = tr_even_fewer_cols\n",
        "val_x_imp = val_even_fewer_cols"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdI4QwcoKmHE"
      },
      "source": [
        "Let's however try scaling one more time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3UZE36yJFW-"
      },
      "source": [
        "tr_x_scaled, val_x_scaled, sc = scale_x(tr_x_imp, val_x_imp)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk5xw8tBMjqf",
        "outputId": "8b00145b-cf46-45a5-9062-26300ac9545e"
      },
      "source": [
        "sc.mean_, sc.var_"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([9.41371542e+02, 2.87107866e+04, 4.03534363e+00, 8.19882740e+00,\n",
              "        3.05399209e+02, 8.43214756e-02, 2.33833992e+01, 1.10671937e-01,\n",
              "        3.25388669e+01]),\n",
              " array([4.54764177e+06, 9.96458782e+09, 4.26376589e-02, 1.44276496e+01,\n",
              "        2.87652912e+04, 7.72113644e-02, 9.95719935e+02, 1.22139074e-01,\n",
              "        4.62077211e+02]))"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNVt3CqjMmuA",
        "outputId": "0a76ff35-05ef-4f20-a66d-5634ea2dd2f8"
      },
      "source": [
        "tr_x_scaled[:3]"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4203344 ,  0.29495485, -0.79415813, -0.05234539, -0.48583484,\n",
              "        -0.3034573 ,  1.12871388, -0.31667239, -1.28111699],\n",
              "       [-0.39313653, -0.08247402, -0.60536346,  1.00073663, -0.55069206,\n",
              "        -0.3034573 , -0.20229419, -0.31667239,  0.81229756],\n",
              "       [-0.35421545, -0.28473246, -1.48277699,  1.52727764, -0.89266647,\n",
              "        -0.3034573 , -0.36074753, -0.31667239, -1.04851538]])"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdP34s7fMwWE",
        "outputId": "2a300ad2-a997-45b6-d21f-bd9b99210944"
      },
      "source": [
        "rfc = rf(tr_x_scaled, tr_y)\n",
        "get_f1_accuracy(rfc, val_x_scaled, val_y)"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7904191616766467"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EeKls2LNNZ5"
      },
      "source": [
        "Not real improvement here. I suppose this is as good as I can polish the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGIwcHM1NgYg"
      },
      "source": [
        "## Trial 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSSmy4awQqdp"
      },
      "source": [
        "One problem of our model can be revealed by observing the confusion matrix. Our predictions are heavily biased towards the mean.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "j8QeasH2NDo4",
        "outputId": "527880df-b0a1-4f52-f389-b8ad49e50574"
      },
      "source": [
        "mat = confusion_matrix(val_y, pred_val)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uicmglJUokzp"
      },
      "source": [
        "Perhaps this bias issue can be solved with some hyperparameter tweaking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "-syVSl0OsjxB",
        "outputId": "821d9e56-780f-41bf-b353-6fa529761bd3"
      },
      "source": [
        "# plot f1_score as n_estimators is steadily increased from 10 to 1000 with intervals of 100\n",
        "plt.plot([get_f1_accuracy(rf(tr_x_imp, tr_y, n_estimators=i), val_x_imp, val_y) for i in range(10,1000,100)])"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f39d8255810>]"
            ]
          },
          "metadata": {},
          "execution_count": 327
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuE4oeljuisT"
      },
      "source": [
        "It seems from here that accuracy is higher the more trees we have but with diminishing returns. So the optimal value seems to be about 600."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-dt9VkGv4BB",
        "outputId": "20580cd0-2a81-4d4b-e788-d05707062d86"
      },
      "source": [
        "get_f1_accuracy(rf(tr_x_imp, tr_y, n_estimators=600), val_x_imp, val_y)"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7874251497005988"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ozdAaq3xxwC"
      },
      "source": [
        "Let's redefine our random forest with the new n_estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtBayTONxhAC"
      },
      "source": [
        "def rf(xs, y, n_estimators=600, max_samples=425,\n",
        "       max_features=0.5, min_samples_leaf=5, max_leaf_nodes=400, **kwargs):\n",
        "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features,\n",
        "        min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes, oob_score=True).fit(xs, y)\n",
        "\n"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2YUbl9yx5Y6"
      },
      "source": [
        "## Trial 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqD1tAOIyG3L"
      },
      "source": [
        "Let's continue this sequence by playing with more hyperparameters. The next important hyperparams are `max_features` and `min_samples_leaf`.\n",
        "\n",
        "Let's compare max_features first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lx8_rL2yGiL",
        "outputId": "e5b0f9a0-35d8-4cd4-c5f8-3654a8fb45a2"
      },
      "source": [
        "[get_f1_accuracy(rf(tr_x_imp, tr_y, max_features=i), val_x_imp, val_y) for i in ['sqrt', 'log2', 0.5]]"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7874251497005988, 0.7844311377245508, 0.7844311377245508]"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UX4_fJ84ntX"
      },
      "source": [
        "It appears `sqrt` offers the highest accuracy. So let's switch `max_features` to that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3z55i4c5TCp"
      },
      "source": [
        "def rf(xs, y, n_estimators=600, max_samples=425,\n",
        "       max_features='sqrt', min_samples_leaf=5, max_leaf_nodes=400, **kwargs):\n",
        "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features,\n",
        "        min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes, oob_score=True).fit(xs, y)"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3f6Pkic6I10"
      },
      "source": [
        "## Trial 10\n",
        "\n",
        "For the final trial I will experiment with `min_samples_leaf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Fv_-BWXi7xZ7",
        "outputId": "e3913615-8dea-41dc-c951-b610a435179e"
      },
      "source": [
        "# plot f1_score as min_sample_leafs is steadily increased from 1 to 10\n",
        "plt.plot([get_f1_accuracy(rf(tr_x_imp, tr_y, min_samples_leaf=i), val_x_imp, val_y) for i in range(1,20)])"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f39d863b450>]"
            ]
          },
          "metadata": {},
          "execution_count": 334
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf7LN0Ug8IfY"
      },
      "source": [
        "Now it may seem that the graph is trending downwards and hence we should pick the highest value. However a `min_samples_leaf` of 1 will mean even one sample is enough for a leaf node. This may prevent some of the bias but it will also allow for more overfitting. I prefer to instead use the next peak of 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP2BP-5l9dPG"
      },
      "source": [
        "def rf(xs, y, n_estimators=600, max_samples=425,\n",
        "       max_features='sqrt', min_samples_leaf=7, max_leaf_nodes=400, **kwargs):\n",
        "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
        "        max_samples=max_samples, max_features=max_features,\n",
        "        min_samples_leaf=min_samples_leaf, max_leaf_nodes=max_leaf_nodes, oob_score=True).fit(xs, y)"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_poVez6q-IbP",
        "outputId": "aac7f29c-59c6-4074-e23c-d76c0cdbc8ff"
      },
      "source": [
        "rfc = rf(tr_x_scaled, tr_y)\n",
        "get_f1_accuracy(rfc, val_x_scaled, val_y)"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7934131736526946"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOz_dbeaSA_7"
      },
      "source": [
        "This is a pretty good score. I think its okay to stop here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpcwj7JzZbXL"
      },
      "source": [
        "## Submission Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFDGwh5943U"
      },
      "source": [
        "Finally, I am done tweaking as much as I could. 😭😭😭\n",
        "\n",
        "Let's generate an output so we can submit the results to the leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOR2NdaxQjis"
      },
      "source": [
        "# once you are happy with your local model, let's prepare a submission\n",
        "# we need to apply the same preprocessing steps on the testing set as you did before you train the model\n",
        "\n",
        "test_data = pd.read_csv('./drive/MyDrive/Colab Notebooks/test_new.csv').sample(frac=1) \n",
        "_id = test_data['id']\n",
        "test_data = test_data.fillna(0)\n",
        "test_data = test_data.drop(['merchant_id', 'merchant_profile_picture', 'id', 'tags'], axis=1)\n",
        "test_data[cat_cols] = test_data[cat_cols].apply(lambda col: col.map(dict_cat[col.name]))\n",
        "\n",
        "# again, not-seen string value filled with -1\n",
        "test_data = test_data.fillna(-1)\n",
        "\n",
        "test_data_imp = test_data[tr_x_imp.columns]"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcR09IYDSnad"
      },
      "source": [
        "Remember that we need to acale the test features the same way we scaled our training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suEt4xZhU-kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637a1239-6d12-4fd3-b4c9-4245d4eb676a"
      },
      "source": [
        "test_data_scaled = sc.transform(test_data_imp)\n",
        "test_data_scaled[:3]"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4170519 , -0.23809982,  0.40198556, -0.62364239, -1.80656359,\n",
              "        -0.3034573 ,  1.28716723, -0.31667239,  0.81229756],\n",
              "       [-0.43487119,  0.14233438,  0.34202046, -1.41871931,  0.59315337,\n",
              "        -0.3034573 ,  0.30475651, -0.31667239, -1.46719829],\n",
              "       [-0.40063939, -0.28529346, -1.73674964, -0.5788864 , -0.91625091,\n",
              "        -0.3034573 , -0.42412887, -0.31667239, -1.37415764]])"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9wqslZXUB3J",
        "outputId": "af64854d-9173-498c-8f7a-f971310bf305"
      },
      "source": [
        "test_data_scaled.shape, tr_x_scaled.shape"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((479, 9), (759, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3fdMMI4UGM8"
      },
      "source": [
        "pred_test = rfc.predict(test_data_scaled)\n",
        "pred_df = pd.DataFrame(data={'id': np.asarray(_id), 'rating': pred_test})\n",
        "pred_df.to_csv('preds_rohan.csv', index=False)"
      ],
      "execution_count": 342,
      "outputs": []
    }
  ]
}